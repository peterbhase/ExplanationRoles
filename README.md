# When Can Models Learn From Explanations?

This is the codebase for the paper: "[When Can Models Learn From Explanations? A Formal Framework for Understanding the Roles of Explanation Data](https://arxiv.org/abs/2102.02201)"

Here's the directory structure:

```
data/ --> data folder (files too large to upload here but are publicly available)
models/ --> contains special model classes for use with retrieval model
training_reports/ --> folder to be populated with individual training run reports
result_sheets/ --> contains special model classes for use with retrieval model
figures/ --> contains plots generated by plots.Rmd
main.py --> main script for all individual experiments in the paper
make_SNLI_data.py --> convert e-SNLI .txt files to .csv's
plots.Rmd --> R markdown file that makes plots using .csv's in result_sheets
report.py --> experiment logging class, reports appear in training_reports
retriever.py --> class for retrieval model
run_tasks.py --> script for running several experiments for each RQ in the paper
utils.py --> data loading and miscellaneous utilities
write_synthetic_data.py --> script for writing synthetic datasets
```

The code is written in Python 3.6. `plots.Rmd` is an R markdown file that makes the plots for each experiment. The package requirements are:

```
torch==1.4
transformers==3.3.1
faiss-cpu==1.6.3
pandas==1.0.5
numpy==1.18.5
scipy==1.4.1
sklearn==0.23.1
argparse==1.1
json==2.0.9
```

Experimental results in the paper are replicated by running `run_tasks.py` with a special experiment command. Below, we give commands organized by the corresponding research question in the paper. For synthetic data experiments, all that is required is that you first set `save_dir` and `cache_dir` in `main.py`. We later give instructions for downloading and formatting data for experiments with existing datasets.

The `run_tasks.py` script can take a few additional arguments when desired: `--seeds` gives the number of seeds to run for each session, and `--train_batch_size` and `--grad_accumulation_factor` can be used to control the effective train batch size and memory usage. 

*RQ1*

python run_tasks.py --gpu GPU --experiment memorization_by_num_tasks

*RQ2*

python run_tasks.py --gpu GPU --experiment missing_by_learning

*RQ3*

*RQ4*

*RQ5*

*RQ6*

*RQ7*

*RQ8*

Each of the remaining experiments has its own corresponding command. 

semeval_baseline
semeval_textcat
semeval_textcat_by_context

tacred_baseline
tacred_textcat
tacred_textcat_by_context

esnli_baseline
esnli_textcat
esnli_textcat_by_context

memorization_by_n
memorization_by_num_tasks
memorization_by_r_smoothness
memorization_by_seed_test

missing_by_learning
missing_by_k
missing_by_rb
missing_by_r_smoothness 
missing_by_feature_correlation   
missing_opt_by_translate_model_n
missing_by_seed_test

evidential_by_learning
evidential_opt_by_method_c
evidential_opt_by_method_n
evidential_by_c
evidential_by_k
evidential_by_init
evidential_by_retriever
evidential_by_seed_test

recomposable_by_learning
